{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import pipeline","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:03:27.928281Z","iopub.execute_input":"2024-03-29T12:03:27.929199Z","iopub.status.idle":"2024-03-29T12:03:56.965183Z","shell.execute_reply.started":"2024-03-29T12:03:27.929150Z","shell.execute_reply":"2024-03-29T12:03:56.963963Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-29 12:03:38.059457: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-29 12:03:38.059596: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-29 12:03:38.263266: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"generator = pipeline(model=\"openai-community/gpt2\")\ngenerator(\"I can't believe you did such a \", do_sample=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-29T12:04:04.107448Z","iopub.execute_input":"2024-03-29T12:04:04.107837Z","iopub.status.idle":"2024-03-29T12:04:11.664202Z","shell.execute_reply.started":"2024-03-29T12:04:04.107804Z","shell.execute_reply":"2024-03-29T12:04:11.662990Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3457fd9b251f495c960a2b172ea0ca03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df641aef846c493f9da66e5977888d51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"141d4e15b6914065aef24e7144747805"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7664d7223af44bbb600b52bc3aed777"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cacb9b73c3574265af7806db76f9e4ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3eb0ad2c3804676968ab24f6e4799b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54eb15e6e6a74438910ff7ab3eae2e96"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': \"I can't believe you did such a icky thing to me. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I\"}]"},"metadata":{}}]},{"cell_type":"code","source":"!pip install cohere","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:19:41.891675Z","iopub.execute_input":"2024-03-29T12:19:41.892341Z","iopub.status.idle":"2024-03-29T12:20:00.308451Z","shell.execute_reply.started":"2024-03-29T12:19:41.892306Z","shell.execute_reply":"2024-03-29T12:20:00.307024Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting cohere\n  Downloading cohere-5.1.7-py3-none-any.whl.metadata (3.0 kB)\nCollecting fastavro<2.0.0,>=1.9.4 (from cohere)\n  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\nRequirement already satisfied: httpx>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from cohere) (0.27.0)\nRequirement already satisfied: pydantic>=1.9.2 in /opt/conda/lib/python3.10/site-packages (from cohere) (2.5.3)\nRequirement already satisfied: requests<3.0.0,>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from cohere) (2.31.0)\nCollecting types-requests<3.0.0.0,>=2.31.0.20240311 (from cohere)\n  Downloading types_requests-2.31.0.20240311-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: typing_extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from cohere) (4.9.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (4.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (1.0.4)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (3.6)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9.2->cohere) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9.2->cohere) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->cohere) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->cohere) (1.26.18)\nCollecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.31.0->cohere)\n  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.21.2->cohere) (1.2.0)\nDownloading cohere-5.1.7-py3-none-any.whl (145 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.3/145.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading types_requests-2.31.0.20240311-py3-none-any.whl (14 kB)\nDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: urllib3, fastavro, types-requests, cohere\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.18\n    Uninstalling urllib3-1.26.18:\n      Successfully uninstalled urllib3-1.26.18\n  Attempting uninstall: fastavro\n    Found existing installation: fastavro 1.9.3\n    Uninstalling fastavro-1.9.3:\n      Successfully uninstalled fastavro-1.9.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\nbotocore 1.34.51 requires urllib3<2.1,>=1.25.4; python_version >= \"3.10\", but you have urllib3 2.2.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cohere-5.1.7 fastavro-1.9.4 types-requests-2.31.0.20240311 urllib3-2.1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom transformers import Pipeline\nimport cohere\nimport json\n\nclass LLMEndpointPipeline(Pipeline):\n    def __init__(self, endpoint, *args, **kwargs):\n        # super().__init__(*args, **kwargs)\n        self.endpoint = endpoint\n        self.cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n        if not self.cohere_api_key:\n            raise ValueError(\"Cohere API key not found in environment variables.\")\n\n        self.cohere_client = cohere.Client(self.cohere_api_key)\n\n    def __call__(self, inputs):\n        # Tokenization\n        # inputs = self.tokenizer(inputs, return_tensors=\"pt\")\n\n        # Model Inference\n        outputs = self.send_to_endpoint(inputs)\n\n        # Post-Processing\n        processed_output = self.post_process(outputs)\n\n        return processed_output\n\n    def send_to_endpoint(self, inputs):\n        # Send inputs to the Cohere API for text generation\n        # prompt = inputs['input_ids'].tolist()[0]  # Assuming tokenized input is in input_ids\n        response = self.cohere_client.generate(prompt=inputs).json()\n        response = json.loads(response)\n        generated_text = response['generations'][0]['text']  # Assuming only one generation\n        return generated_text\n\n    def post_process(self, outputs):\n        # Placeholder for post-processing\n        # This method can be used for any additional processing of the generated text\n        return [{\"generated_text\": outputs}]\n\n    def _forward(self, *args, **kwargs):\n        # Implement forward method for Pipeline abstract class\n        pass\n\n    def _sanitize_parameters(self, *args, **kwargs):\n        # Implement parameter sanitization method for Pipeline abstract class\n        pass\n\n    def preprocess(self, *args, **kwargs):\n        # Implement preprocessing method for Pipeline abstract class\n        pass\n\n    def postprocess(self, *args, **kwargs):\n        # Implement postprocessing method for Pipeline abstract class\n        pass","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:43:25.974992Z","iopub.execute_input":"2024-03-29T12:43:25.975401Z","iopub.status.idle":"2024-03-29T12:43:25.994502Z","shell.execute_reply.started":"2024-03-29T12:43:25.975368Z","shell.execute_reply":"2024-03-29T12:43:25.992855Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Example usage\nllm_pipeline = LLMEndpointPipeline(model=None, tokenizer=None, endpoint=\"https://api.cohere.ai/v1/generate\")\n\ninput_text = \"I can't believe you did such a \"\noutput = llm_pipeline(input_text)\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:42:15.207935Z","iopub.execute_input":"2024-03-29T12:42:15.208986Z","iopub.status.idle":"2024-03-29T12:42:20.093932Z","shell.execute_reply.started":"2024-03-29T12:42:15.208950Z","shell.execute_reply":"2024-03-29T12:42:20.092608Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"[{'generated_text': \"I'm sorry to hear that. I am an AI language model that is trained to have polite, helpful, and inclusive conversations with users. I adhere to ethical and responsible principles in my responses. Could you please clarify what you are referring to? I am happy to address any concerns or mistakes that I may have made previously, or perhaps alleviate any misconceptions you may have. \"}]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}